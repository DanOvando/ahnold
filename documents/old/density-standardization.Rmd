---
title: "Density Standardization"
output:
  html_document: default
---

```{r setup, include=F}
knitr::opts_chunk$set(warning = F, message = F)
```

This is a new angle on the MLPA effects. You still haven't ever addressed the zeros in the database, which after diving you're seeing is definitely an issue. It remains really unclear to me how you'd create a joint DiD estimator, without going down a tobit route, and the tobit doesn't seem to work at all in this context since the data are so heavily zero inflated. 

On top of that, with all the damn coefficients in the model it's getting really hard to make sure that you're isloating what you think you're isolating. 

So what if instead you make this something like a two-part model. 

Part one will be a standaridization of the densitiy indicies in a standard delta-glm fashion. You can obviously fancy that up a lot but as a starting point. 

You'll fit one model the the positive densities, and another to the probability of observation, by species. You'll then extract the year terms from the positive densities, and create a standardized probability of observation as the probability of observing across the years, holding other factors constant. There will be no "mpa effect" in this part of the model. 

This will create a net abundance index by species over time, potentially by region as well if you want to get fancy, but let's start simple. 

Once you have that in place, you now fir the DiD estimator to try and extract the MLPA effect from the overall abundance trend. This will be the part where you incorporate things like ENSO, temperature, etc, to try and tease out the MPA from environmental drivers. This also gets you out of the weighting issue, where increased observations by species might be biasing your results. 

Let's see what happens. 

```{r load-life}
library(sf)
library(scales)
library(rstanarm)
library(scales)
library(viridis)
library(ggmap)
library(tidyverse)
library(forcats)
library(stringr)
library(lubridate)
library(purrr)
demons::load_functions('../functions')
```

Copy and pasting from `run_ahonold.R`
```{r load-data}

# set options ------------------------------
# Summary: set options for model run

run_name <- 'Working'

run_dir <- file.path('../results', run_name)

run_description <-
  'Model selection process, testing STAN selection'

if (dir.exists(run_dir) == F) {
  dir.create(run_dir)
}

write(run_description,
      file = paste(run_dir, 'RUN_DESCRIPTION.txt', sep = '/'))

# set run parameters ------------------------------
# Summary: set things like filters

run_vast <- F

aggregate_transectsÂ  <- F

channel_islands_only <- T

min_year <- 1999

occurance_ranking_cutoff <- 0.5

small_num <-  0

use_mpa_site_effects <- F

# load Data ------------------------------
# Summary: Bring in required data for project

length_data <- read_csv('../data/UCSB_FISH raw thru 2013.csv') %>%
  magrittr::set_colnames(., tolower(colnames(.)))

life_history_data <-
  read_csv('../data/VRG Fish Life History in MPA_04_08_11_12 11-Mar-2014.csv') %>%
  rename(classcode = pisco_classcode) %>%
  mutate(classcode = tolower(classcode)) %>%
  # rename(description_2 = Description) %>%
  magrittr::set_colnames(., tolower(colnames(.)))

site_data <- read_csv('../data/Final_Site_Table_UCSB.csv') %>%
  magrittr::set_colnames(., tolower(colnames(.))) %>%
  select(site,side,mpagroup, mpa_status, reserve, region, year_mpa,mpaareanm2) %>%
  unique()

length_data <- length_data %>%
  left_join(life_history_data %>% mutate(classcode = toupper(classcode)), by = 'classcode') #%>%
  # left_join(site_data, by = c('site', 'side'))

ci_catches <- read_csv(file = file.path('../data','cfdw-channel-islands-catches.csv')) %>% group_by(classcode, year) %>% 
  summarise(catch = sum(pounds_caught, na.rm = T))

fished_species <- data_frame(classcode = unique(ci_catches$classcode), fished = 1)


conditions_data <- length_data %>%
  group_by(site,side, year) %>%
  summarise(
    mean_temp = mean(temp, na.rm = T),
    mean_kelp = mean(pctcnpy, na.rm = T),
    mean_vis = mean(vis, na.rm = T)
  )


density_data <- read_csv('../data/ci_reserve_data_final3 txt.csv') %>%
  magrittr::set_colnames(., tolower(colnames(.))) %>%
  gather('concat.name', 'value', grep('_', colnames(.)), convert = T) %>%
  mutate(
    data.type = gsub('\\_.*', '', concat.name),
    classcode = gsub('.*\\_', '', concat.name)
  ) %>%
  mutate(value = as.numeric(value)) %>%
  spread(data.type, value) %>%
  rename(site_side = site.side)



site_coords <- density_data %>% 
  group_by(site, side) %>% 
  summarise(latitude = mean(lon.wgs84, na.rm = T),
            longitude = mean(lat.wgs84, na.rm = T))

# ggmap::qmplot(longitude,latitude, color = side, data = site_coords)


if (file.exists('../data/enso.csv')) {
  enso <- read_csv('../data/enso.csv') %>%
    group_by(year) %>%
    summarise(mean_enso = mean(enso, na.rm = T)) %>%
    mutate(lag1_enso = dplyr::lag(mean_enso,1),
           lag2_enso = dplyr::lag(mean_enso,2),
           lag3_enso = dplyr::lag(mean_enso,3),
           lag4_enso = dplyr::lag(mean_enso,4))

} else {
  scrape_enso(outdir = '../data/')

}

if (file.exists('../data/pdo.csv')) {
  pdo <- read_csv('../data/pdo.csv') %>%
    group_by(year) %>%
    summarise(mean_pdo = mean(pdo, na.rm = T)) %>%
    mutate(lag1_pdo = dplyr::lag(mean_pdo,1),
           lag2_pdo = dplyr::lag(mean_pdo,2),
           lag3_pdo = dplyr::lag(mean_pdo,3),
           lag4_pdo = dplyr::lag(mean_pdo,4))

} else {
  scrape_pdo(outdir = '../data/')

  pdo <- read_csv('../data/pdo.csv') %>%
    group_by(year) %>%
    summarise(mean_pdo = mean(pdo, na.rm = T)) %>%
    mutate(lag1_pdo = dplyr::lag(mean_pdo,1),
           lag2_pdo = dplyr::lag(mean_pdo,2),
           lag3_pdo = dplyr::lag(mean_pdo,3),
           lag4_pdo = dplyr::lag(mean_pdo,4))

}

# prepare data----------------------------
# Summary: apply transformations, calculations etc.

has_all <- function(x,reg_vars)
  any(is.na(x[reg_vars])) == F


reg_vars <- c('log_density', 'year','targeted',
              'mean_enso','mean_pdo', 'mean_temp','classcode','site','side','post_mlpa',
              'trophicgroup')

reg_data <- density_data %>%
  select(biomass, site,side,site_side, year, classcode) %>%
  # group_by(site,side, year, classcode) %>%
  # summarise(mean_density = mean(biomass, na.rm = T)) %>%
  ungroup() %>%
  left_join(conditions_data, by = c('site','side', 'year')) %>%
  left_join(life_history_data %>% select(classcode, targeted, trophicgroup,
                                         commonname),
            by = 'classcode') %>%
  left_join(enso, by = 'year') %>%
  left_join(pdo, by = 'year') %>%
  # left_join(site_data %>% select(site,side,region,year_mpa), by = c('site','side')) %>%
  mutate(
    any_seen = biomass > 0,
    log_density = log(biomass),
    targeted = as.numeric(targeted == 'Targeted'),
    post_mlpa = as.numeric(year >= 2003)
  ) %>%
# select_(.dots = as.list(reg_vars)) %>%
  map2_df(
    colnames(.),
    center_scale,
    omit_names = c('log_density','biomass', 'year', 'mean_enso', 'mean_pdo',
                   'targeted','year_mpa',paste0('lag',1:4,'_enso'),paste0('lag',1:4,'_pdo'))
  ) %>%
  mutate(log_density = log(biomass + small_num)) #%>%
 
```

`density_data` then is your basic density data provided by Jen. Let's also create `length_to_density_data` as an alternative, allowing you to more explicitly account for observer effects. 

Pulling from `ahnold_labbook.Rmd`

```{r create-density-from-length}

density_example <- density_data %>% 
  filter(is.na(biomass) == F & biomass >0) %>% 
  sample_n(1)


length_example <- length_data %>% 
  filter(classcode == toupper(density_example$classcode)
, site == density_example$site, 
         side == density_example$side, year == density_example$year) 

length_example <-   length_data %>% 
  filter(is.na(commonname) == F) %>% 
  mutate(biomass_g = pmap_dbl(list(mean_length = fish_tl,
                                      min_length = min_tl,
                                      max_length = max_tl,
                                      count = count,
                                      weight_a = wl_a,
                                      weight_b = wl_b,
                                      length_type_for_weight = wl_input_length,
                                      length_for_weight_units = wl_l_units,
                                      tl_sl_a = lc.a._for_wl,
                                      tl_sl_b = lc.b._for_wl,
                                      tl_sl_type = lc_type_for_wl,
                                      tl_sl_formula = ll_equation_for_wl), length_to_weight))

length_to_density_data <- length_example %>% 
  mutate(observer = ifelse(is.na(observer), 'unknown',observer),
         surge = ifelse(is.na(observer), 'unknown',surge)) %>% 
  group_by(classcode, site, side, year, transect, observer) %>% 
  summarise(total_biomass_g = sum(biomass_g),
            mean_temp = mean(temp, na.rm = T),
            mean_vis = mean(vis, na.rm = T),
            mean_depth = mean(depth, na.rm = T),
            mean_canopy = mean(pctcnpy, na.rm = T)
            ) 

length_to_density_data %>% 
  summarise(nobs = length(classcode))

species_sightings <- length_data %>% 
  left_join(site_data, by = 'site') %>% 
  group_by(region) %>% 
  summarise(species_seen = list(unique(classcode)))



length_to_density_data <- length_to_density_data %>% 
  ungroup() %>% 
  left_join(site_data %>% select(site, region), by = 'site') %>% 
  select(region,site,side,year, transect) %>% 
  unique() %>%  {
  pmap(
    list(
      this_region = .$region,
      this_site = .$site,
      this_side = .$side,
      this_year = .$year,
      this_transect = .$transect
    ),
    add_missing_fish,
    observations = length_to_density_data,
    species_sightings = species_sightings
  )
} %>% 
  bind_rows()


if (aggregate_transects == T){
length_to_density_data <- length_to_density_data %>% 
  group_by(classcode, observer, site, side,year) %>% 
  summarise(mean_biomass_g = mean(total_biomass_g, na.rm = T),
             mean_temp = mean(mean_temp, na.rm = T),
            mean_vis = mean(mean_vis, na.rm = T),
            mean_depth = mean(mean_depth, na.rm = T),
            mean_canopy = mean(mean_canopy, na.rm = T)) %>% 
  mutate(
            biomass_g_per_m2 = mean_biomass_g / (30*4),
            biomass_g_per_hectare = biomass_g_per_m2 * 10000,
            biomass_ton_per_hectare = biomass_g_per_hectare * 1e-6
           ) %>% 
  ungroup()
} else {
  
  length_to_density_data <- length_to_density_data %>% 
  rename(mean_biomass_g = total_biomass_g) %>% 
  mutate(
            biomass_g_per_m2 = mean_biomass_g / (30*4),
            biomass_g_per_hectare = biomass_g_per_m2 * 10000,
            biomass_ton_per_hectare = biomass_g_per_hectare * 1e-6
           ) %>% 
  ungroup()

  
}

save(file = paste0(run_dir, '/length_to_density_data.Rdata'), length_to_density_data)


```



OK, now you've got data to play with. 

Let's explore fitting the regression objects for each of the data objects (manually created and supplied densities). The end goal is to be able to compare the raw and standardized abundance indicies by species over time. 

```{r aggregate data}

raw_length_vars <- paste(c('factor_year:region','observer', 'site','mean_vis','mean_canopy'), collapse = '+')

supplied_density_vars <- paste(c('factor_year:region', 'site','mean_kelp', 'mean_vis'), collapse = '+')

prob_raw_length_vars <- paste(c('factor_year','observer', 'site','mean_vis','mean_canopy'), collapse = '+')

prob_supplied_density_vars <- paste(c('factor_year','region', 'site','mean_kelp', 'mean_vis'), collapse = '+')


length_to_density_data <- length_to_density_data %>% 
  mutate(any_seen = mean_biomass_g > 0, 
         factor_year = factor(year),
         log_density = log(mean_biomass_g)) %>% 
  group_by(site, side,year) %>% 
  mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_canopy = ifelse(is.na(mean_canopy), mean(mean_canopy, na.rm = T), mean_canopy)) %>% 
  group_by(site,year) %>% 
    mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_canopy = ifelse(is.na(mean_canopy), mean(mean_canopy, na.rm = T), mean_canopy)) %>% 
  group_by(year) %>% 
    mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_canopy = ifelse(is.na(mean_canopy), mean(mean_canopy, na.rm = T), mean_canopy)) %>% 
  ungroup() %>% 
    mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_canopy = ifelse(is.na(mean_canopy), mean(mean_canopy, na.rm = T), mean_canopy))
  

density_data <- reg_data %>% 
  mutate(factor_year = factor(year), 
         log_density = log(biomass)) %>% 
   group_by(site, side,year) %>% 
  mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_kelp = ifelse(is.na(mean_kelp), mean(mean_kelp, na.rm = T), mean_kelp)) %>% 
  group_by(site,year) %>% 
    mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_kelp = ifelse(is.na(mean_kelp), mean(mean_kelp, na.rm = T), mean_kelp)) %>% 
  group_by(year) %>% 
    mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_kelp = ifelse(is.na(mean_kelp), mean(mean_kelp, na.rm = T), mean_kelp)) %>% 
  ungroup() %>% 
    mutate(mean_vis = ifelse(is.na(mean_vis), mean(mean_vis, na.rm = T), mean_vis),
         mean_kelp = ifelse(is.na(mean_kelp), mean(mean_kelp, na.rm = T), mean_kelp))


length_to_density_models <- length_to_density_data %>% 
  nest(-classcode) %>% 
  mutate(ind_vars = raw_length_vars,
         prob_ind_vars = prob_raw_length_vars)

supplied_density_models <- density_data %>% 
  nest(-classcode) %>% 
  mutate(ind_vars = supplied_density_vars,
         prob_ind_vars = prob_supplied_density_vars)

length_to_density_models <- length_to_density_models %>% 
  mutate(data_source = 'length_to_density')

supplied_density_models <- supplied_density_models %>% 
  mutate(data_source = 'supplied_density')


```
# Run filers
```{r filter-and-process-data}


filterfoo <- function(x, min_seen_years = 8, mpa_start_year = 2003){ # only years above 1999 at the main channel islands
  
  x <- x %>% 
    filter(is.na(log_density) == F) %>% 
  filter(year > 1999 & region %in% c('ANA','SCI','SMI','SRI')) %>% 
    group_by(region) %>% 
    mutate(num_years_observed = length(unique(year[any_seen == T])),
           min_year = min(year[any_seen == T], na.rm = T),
           max_year = max(year[any_seen == T], na.rm = T)) %>% 
    ungroup() %>% 
    filter(num_years_observed >= min_seen_years,
           min_year <= mpa_start_year,
           max_year >= mpa_start_year) # actually observed for at least 10 years
}


site_data <- site_data %>% 
  mutate(eventual_mpa = (year_mpa >0))

abundance_models <- length_to_density_models %>% 
  bind_rows(supplied_density_models) %>% 
  mutate(data = map(data, ~left_join(.x, site_data, by = c('site','side')))) %>% 
  mutate(data = map(data, (filterfoo))) %>% # filter out things
  mutate(dim_data = map_dbl(data, nrow)) %>% 
  filter(dim_data > 0) %>%  # remove fisheries that didn't pass filterfoo
  mutate(classcode = tolower(classcode)) %>% 
  left_join(life_history_data %>% select(classcode, commonname, targeted), by = 'classcode') %>% 
  left_join(fished_species, by = 'classcode') %>% 
  mutate(targeted = ifelse(fished == 1 & is.na(fished) == F & targeted == "Non-targeted", 'Targeted', targeted)) %>% 
  filter(str_detect(commonname, 'YOY') == F, is.na(targeted) == F) %>% 
  mutate(data = map(data, ~ purrrlyr::dmap_if(.x, is.numeric, center_scale))) # center and scale continuos data

abundance_models %>% 
  ggplot(aes(commonname, dim_data, fill = data_source)) + 
  geom_col(position = 'dodge') + 
  coord_flip()

abundance_models %>% 
  ggplot(aes(commonname, dim_data, fill = targeted)) + 
  geom_col(position = 'dodge') + 
  coord_flip() + 
  facet_wrap(~data_source)

```


# fit VAST abundance index

Another possibility (likely) is that you're just doing a bad job with the abundance standardization, and maybe VAST would do a better job doing multi-species interactions. Let's see what happens. 

```{r run-vast}

vast_prep <- function(data, classcode,site_coords,conditions_data){
  
  data <- data %>%
    left_join(site_coords, by = c('site', 'side')) %>%
    mutate(
    year = factor_year %>% as.character() %>% as.numeric(),
    areaswept_km2 = (30 * 4) * .001,
    spp = classcode
    )
  
  if (is.null(data$observer)){
    data$observer = 'unknown'
  }
    if (is.null(data$mean_biomass_g)){
    data$mean_biomass_g = data$biomass
  }

 data <- data %>% 
    select(year, latitude, longitude, observer,areaswept_km2, mean_biomass_g, spp, mean_vis) %>% 
    rename(lat = latitude, lon = longitude, vessel = observer, catch_kg = mean_biomass_g) %>% 
    filter(is.na(catch_kg) == F)
  
  data <- data %>% 
    group_by(spp,year) %>% 
    mutate(min_catch = min(catch_kg, na.rm = T),
           npos = sum(catch_kg > 0)) %>% 
    ungroup() %>% 
    mutate(catch_kg = ifelse(catch_kg == min_catch, 0, catch_kg)) %>% 
    filter(npos > 0)
}

vast_abundance <- abundance_models %>% 
    select(classcode, data_source, data) %>% 
  mutate(survey_region = 'california_current',
         n_x = 200) %>% 
  mutate(vast_data = map2(data,classcode, vast_prep, site_coords = site_coords, conditions_data = conditions_data))



if (run_vast == T){
arg <- safely(vasterize_pisco_data)

vast_abundance <- vast_abundance %>% 
      mutate(
      vast_results = purrr::pmap(
        list(
          region = survey_region,
          raw_data = vast_data,
          n_x = n_x
        ),
        arg,
        run_dir = run_dir,
        nstart = 100,
        obs_model = c(2, 0)
      )
    )

vast_abundance <- vast_abundance %>% 
  mutate(vast_error = map(vast_results, 'error'))

save(file = paste0(run_dir,'/vast_abundance.Rdata'), vast_abundance)
} else {
  
  load(file = paste0(run_dir,'/vast_abundance.Rdata'))

  
}

vast_abundance <- vast_abundance %>% 
  mutate(vast_index = map(vast_results,'result'))

a <- vast_abundance$vast_index[[19]]$spatial_densities 
  ggmap::qmplot(approx_long, approx_lat, data = a, color = density) + 
    facet_wrap(~year) + 
    theme_minimal() +
    scale_color_viridis()



vast_abundance$vast_index[[1]]$time_index %>% View()
a
```


# vit manual delta glm

OK that seemed to work!

```{r fit-models}


abundance_models <- abundance_models %>% 
  mutate(seen_model = map2(data,ind_vars, safely_fit_fish, dep_var = 'log_density', fit_seen = T, family = 'gaussian'),
         seeing_model =map2(data,prob_ind_vars, safely_fit_fish, dep_var = 'any_seen', fit_seen = F, family = 'binomial') )

abundance_models <- abundance_models %>% 
  mutate(seeing_error = map(seeing_model, 'error'),
         seen_error =  map(seen_model, 'error'),
         seeing_model = map(seeing_model, 'result'),
         seen_model =  map(seen_model, 'result'))


```


```{r}


abundance_models <- abundance_models %>% 
  mutate(no_error = map2_lgl(seeing_error, seen_error, ~is.null(.x) & is.null(.y))) %>% 
  filter(no_error == T)


abundance_models <- abundance_models %>% 
  mutate(seen_coefs = map(seen_model, broom::tidy),
         seen_aug = map(seen_model, broom::augment),
         seeing_coefs = map(seeing_model, broom::tidy),
         seeing_aug = map(seeing_model, broom::augment))


```

Strategy for getting out year terms in this thing. Rather than losing a year of data you need to actually consider the intercept in there. 

Write a function to deal with all this, using `model$xlevels` to see the available levels and see what you're missing, just to make sure the years are relative to what you think they are. 

So, what you want to do is for each regression, figure out what the intercept actually means, and include that. Then, back transform all the year terms as the intercept + sigma^2/2 + year_terms + sigma^2/2, and the put all that in an appropriate data frame. 

For the year-by-year probabilities, generate a fake data frame by year holding the other things constant, and then changing year, and getting the predicted probabilities back from that  process, in the same data frame, and then just `bind_cols` and multiply to get your abundance index

Still struggling with getting the omitted year out. One simple approach could be to set up your "constant" case, which is a dataframe that holds everything else constant extcept for the years, including the dropped year, and get the estimated abundance trend from that, and then back transform to normal space with a smearing estimate. 

If you theory is right, then plotting the log density for that site and that observer against the model predicted trend should look like something reasonable, or at least be on the same order og magnitude

As your check, look at the trend done the normal way, and comapre to the trend this way; they should more or less be identical except for the one more data point



```{r}


abundance_models <- abundance_models %>%
  mutate(abundance_index = pmap(
  list(
  seen_model = seen_model,
  seeing_model = seeing_model,
  seeing_aug = seeing_aug,
  seen_aug = seen_aug
  ),
  create_abundance_index,
  model_resolution = 'regional'
  ))

abundance_models <- abundance_models %>% 
  mutate(abundance_plot = map(abundance_index, ~ ggplot(.x,aes(factor_year %>% as.character() %>% as.numeric(), abundance_index, color = region)) + geom_line()))

abundance_models <- abundance_models %>% 
  mutate(num_years = map_dbl(abundance_index, ~ nrow(.x)))


consistent_models <- abundance_models %>% 
  # filter(num_years >=10) %>% 
  mutate(classcode = tolower(classcode))

walk2(consistent_models$commonname, consistent_models$abundance_plot,
      ~ ggsave(file = paste0(run_dir,'/',.x,'.pdf'), .y), run_dir = run_dir)

consistent_models$abundance_plot[[3]]

```

So here's the plot you want. By species, what you want is the normalized abundance defined as 1) mean from the supplied data 2) mean from the length derived data 3) mean from model from length 4) mean from model from suppled 

```{r}

calc_raw_abundance <- function(data) {

  if (any(colnames(data) == 'biomass')){
    
    data$mean_biomass_g <- data$biomass
    
  }
  
  raw_trend <- data %>% 
    group_by(region,factor_year) %>% 
    summarise(abundance_index = mean(mean_biomass_g, na.rm = T)) %>% 
    ungroup() %>% 
    mutate(abundance_index = center_scale(abundance_index + 1e-3)) %>% 
    mutate(year = factor_year %>% as.character() %>% as.numeric()) %>% 
    ungroup()
  
}

model_plots <- consistent_models %>% 
  mutate(standardized_abundance_trend = map(abundance_index, ~select(.,factor_year,region,abundance_index) %>% mutate(year = as.character(factor_year) %>% as.numeric()))) %>% 
  mutate(raw_abundance_trend = map(data,calc_raw_abundance )) %>% 
  select(classcode,data_source,standardized_abundance_trend,raw_abundance_trend)


raw_model_plots <- model_plots %>% 
  select(classcode, data_source, raw_abundance_trend) %>% 
  unnest() %>% 
  mutate(abundance_source = 'raw')

standardized_model_plots <- model_plots %>% 
  select(classcode, data_source, standardized_abundance_trend) %>% 
  unnest() %>% 
  mutate(abundance_source = 'standardized')


vast_model_plots <- vast_abundance %>% 
  mutate(time_index = map(vast_index, 'time_index')) %>% 
  select(classcode, data_source,time_index) %>% 
  unnest() %>% 
  mutate(factor_year = as.factor(Year),
         region = 'SCI') %>% 
  rename(year = Year) %>% 
  select(classcode, data_source,factor_year, region, abundance,year) %>% 
    rename(abundance_index = abundance) %>% 
  set_names(tolower) %>% 
    mutate(abundance_source = 'vast') %>% 
  group_by(classcode, data_source) %>% 
         mutate(abundance_index = center_scale(abundance_index + 1e-3)) %>% 
  ungroup()

model_comparison_plots <- raw_model_plots %>% 
  bind_rows(standardized_model_plots) %>% 
  bind_rows(vast_model_plots) %>% 
  nest(-classcode)

comp_plot_foo <- function(data){
  data %>% 
    ggplot(aes(year, abundance_index, color = abundance_source)) + 
    geom_line() + 
    geom_point() + 
  facet_grid(data_source ~ region)
  
  
}

model_comparison_plots <- model_comparison_plots %>% 
  mutate(comp_plot = map(data, comp_plot_foo)) %>% 
    mutate(classcode = tolower(classcode)) %>% 
  left_join(life_history_data %>% select(classcode, commonname))


save(file = paste0(run_dir,'/model_comparisons.Rdata'), model_comparison_plots)

  
walk2(model_comparison_plots$commonname, model_comparison_plots$comp_plot,
      ~ ggsave(file = paste0(run_dir,'/',.x,'-modelcomp.pdf'), .y), run_dir = run_dir)

```

OK! You've got standardized time series now. And it only took a weekend and a few days and nights... Now the key question is, does it actually make a damn difference. 

The goal now is to control for environment and other factors beside the MPA, but now avoiding the need for the super confusing generic year terms and other stuff, though you could in theory control for that too, but your degrees of freedom are going to start mattering really quickly here. YOur new unit of observation is species by year. So, you obviously can't estimate species and year effects, unless you want to go hierarchical, but let's go that route after seeing if the signal itself is any cleaer or different. 

# Fit DiD estimators
So for now in this regression, let's do DiD, plus el nino etc, plus temperature and try a temperature species interaction 


```{r}

annual_conditions <- conditions_data %>% 
  left_join(site_data %>% select(site, region), by = 'site') %>% 
  group_by(region,year) %>% 
  summarise(mean_annual_temp = mean(mean_temp, na.rm = T),
            mean_annual_kelp = mean(mean_kelp, na.rm  = T)) %>% 
  gather(variable, value,-year,-region) %>% 
  group_by(variable) %>% 
  mutate(value = zoo::na.approx(value),
         value = center_scale(value)) %>% 
  spread(variable, value)


did_data <- model_comparison_plots %>% 
  select(classcode, data) %>% 
  unnest() %>% 
  left_join(life_history_data, by = 'classcode') %>% 
  left_join(enso, by = 'year') %>% 
  left_join(pdo, by = 'year') %>% 
  left_join(annual_conditions, by = c('year','region')) %>% 
  left_join(ci_catches, by = c('classcode','year')) %>% 
  mutate(catch = ifelse(is.na(catch), 0, catch))
  
  
interesting <- did_data %>% 
  filter(catch > 0, targeted == 'Non-targeted')
```

OK, now add in DiD estimator... which is the interaction of targeted and being pre or post MLPA. So for that, you're going to do what. You need a volumn that is a 1 if it's a fished species in that year and 0 if it's a fished species not in that year, along with fished species, and post 2003. 

```{r}

did_terms <- did_data %>% 
  select(year, targeted) %>% 
  mutate(index = 1:nrow(.),
         targeted = as.numeric(targeted == 'Targeted')) %>% 
  spread(year, targeted, fill = 0) %>% 
  select(-index) %>% 
  set_names(., paste0('did_',colnames(.))) %>% 
  select(-did_2002)

did_data <- did_data %>% 
    mutate(targeted = as.numeric(targeted == 'Targeted'),
           post_mpa = as.numeric(year >= 2003)) %>% 
  bind_cols(did_terms) 

# did_reg <- paste0('abundance_index ~',paste(c('targeted','post_mpa','mean_enso','mean_pdo','mean_annual_kelp','mean_annual_temp',colnames(did_terms)), collapse = '+'))

did_reg <- paste0('abundance_index ~',paste(c('targeted','post_mpa','mean_enso','mean_pdo','(mean_annual_temp|classcode)','mean_annual_kelp',colnames(did_terms)), collapse = '+'))


did_models <- did_data %>% 
  nest(-data_source,-abundance_source) %>% 
  mutate(did_reg = did_reg) %>% 
  mutate(did_model = map2(data, did_reg, ~lme4::glmer(.y, data = .x)))



did_plot_foo <- function(x) {
 x %>% 
  broom::tidy() %>% 
  filter(str_detect(term, 'did')) %>% 
  mutate(year = str_replace(term,'did_','') %>% as.numeric()) %>% 
  ggplot() + 
  geom_pointrange(aes(year, estimate, ymin = estimate - 1.96 *std.error, ymax = estimate + 1.96 * std.error)) + 
   geom_vline(aes(xintercept = 2003), color = 'red', linetype = 2) + 
   geom_hline(aes(yintercept = 0))
}

did_models <- did_models %>% 
  mutate(did_plot = map(did_model, did_plot_foo))

did_plot_foo <- function(data_source, abundance_source,did_plot, run_dir){
  
   ggsave(file = paste0(run_dir, '/',data_source,'-',abundance_source,'-did.pdf'), did_plot)
}

pwalk(list(data_source = did_models$data_source,
           abundance_source =  did_models$abundance_source,
           did_plot = did_models$did_plot),did_plot_foo, run_dir = run_dir)

```

OK, we're working top to bottom. Next things to do.... center and scale instead of scale by max. CI only. run by region. cross fingers.

# What next?

OK, well that was a solid body of work for relatively little payoff. What have you learned?

  - Standardizing densities doesn't make a huge difference in most cases, but does in some
  - Same story for regional effects
  - DiD estimator fit to those new data aren't really any better, and certainly noisier, than the others. You can certainly squint at them and see a result of some kind, but there's nothing really defensible in there. 
  - So, it's time to make a call here, what are your options?
  
## Do the best job you have with the standardized analysis

GO through and do a more careful job of model fitting, maybe go full bayesian to get the error structure right, etc. But the gist of this one is simple: There is not a detectable causal effect of the MLPA on densities of fished species. 

Now to do this, you'll have to defend 1) the analysis itself 2) defend the "control" 3) something. 

## Go with the old results

After all this, go back and clean up the old methods, under the argument that it's better to control for everything at once. You had "cleaner" results there, and can somewhat go with that "decreasing" story at the beginning, but you'll need to carefully defend that with a plausible story, which it turns out is pretty damn hard to do given the observed history of the fishery. 

## Abandon ship

The worst case one (I think). There's simply not enough clear signal in the data, and there is no suitable control (saying now that fished/unfished doesn't work), to say anything causal. Raw trends and things have been published, so the story here is that MPAs may or may not work, and without a good spatial BACI/DID design you'll simply never know if it "worked"

## Look for alternative controls

lightly vs. heavily fished species? 

Get central coast data?

KFM data?

propensity scores?

Let's step away for a moment or two and then compile a summary document for *one day*


```{r}
did_data %>% 
  group_by(data_source,abundance_source, year,targeted) %>% 
  summarise(mean_abundance = mean(abundance_index, na.rm = T)) %>% 
  filter(abundance_source == 'standardized') %>% 
  ggplot(aes(year, mean_abundance, color = factor(targeted))) + 
  geom_line() + 
  facet_grid(data_source ~ abundance_source, scales = 'free_y')
```

# Save some things

```{r}

save(file = paste0(run_dir,'/did-models.Rdata'), did_models)

save(file = paste0(run_dir,'/abundance-model-data.Rdata'), abundance_models)


```

