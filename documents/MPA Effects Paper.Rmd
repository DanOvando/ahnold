---
title: New draft of MPA effects Paper
author: "Dan Ovando"
date: "December 17, 2015"
output:
  pdf_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 6
  html_document: default
csl: fish-and-fisheries.csl
bibliography: MLPA Effects.bib
---

```{r, include=F}
knitr::opts_chunk$set(fig.path='Figs/', echo=FALSE, warning=FALSE, message=FALSE)

```

```{r load libraries}
library(knitr)
library(gridExtra)
library(ggplot2)
library(plyr)
library(dplyr)
library(tidyr)
library(broom)
library(coda)
library(ggmcmc)
library(LaplacesDemon)
library(foreach)
library(scales)
library(stargazer)
library(DT)
library(ggmap)
library(texreg)
# library(VGAM)
library(AER)
library(msm)
library(mvtnorm)
devtools::load_all('MLPAFuns')
```

```{r load data, cache = T}

# Load this now please
# hours 
 B <- 5
M <- 7
#
runfolder <- '4.1'

runpath <- paste('results/',runfolder,'/', sep = '')

if (dir.exists(runpath) == F)
{
  dir.create(runpath, recursive = T)
}

load(paste(runpath,'reg_data.Rdata', sep = ''))

load(paste(runpath,'MCMC results.Rdata', sep = ''))

load(paste(runpath,'Processed MCMC results.Rdata', sep = ''))

plot_theme <- theme_classic() + theme(text = element_text(size = 18, family = 'Helvetica'))

dat <- processed_demon$predictions

# dat <- out

plots <- processed_demon$plot_list

thinned_post <- as.data.frame(processed_demon$thinned_post)

```


## Introduction

Natural resource management is based on our belief that humans as managers can have a casual impact on the world. If our policies do not cause outcomes, then we may as well relax and go along for nature's ride. However, we are faced then with a challenge. While some policies have intuitively clear outcomes, e.g. catching less fish will leave more fish in the water, other actions have far less clear outcomes, e.g. what are the employment impacts of rights-based fishery management? Management decisions must often be made then in face of uncertainty in the actual effect of our policies. 

To confront this challenge, especially in the murky world of fisheries management, we have often turned to concepts such as management strategy evaluation (MSE) [@Smith1994] to guide policy choices [@Punt2015]. Since we generally cannot experimentally test policies before applying them, we use model simulations to consider the likely outcomes of policies and select those that best meet the objectives of management. While this is a critical tool in the fisheries management toolbox, there still often remains a question: did the enacted policy cause its intended outcome?

This question of causality is rarely addressed in natural resources management. An informal investigation of Google Scholar results for "fisheries + causality" mostly returns papers with the phrase "correlation does not equal causation". Many examples that do exist are more focused on detecting the effects of environmental drivers [e.g. @Sugihara2012]. There are many sound reasons for this. Fisheries, and marine ecosystems in general, are highly complex systems. The environmental, assessment, and management processes introduce vast amounts of uncertainty, and can make the act of teasing apart causation from correlation exceedingly difficult. 

However, the field of economics has a rich history of causal detection in a diversity of complex systems, such as the effects of Individual Transferable Quotas on fishery collapse [@Costello2008], the relationship between alcohol taxes and drunk driving [@Ruhm1996], or the casual effect of Sesame Street on school readiness [@Kearney2015]. While still challenging (and often dependent on fortuitous natural experiments), econometric techniques provide a robust and underutilized avenue for exploring causality in fisheries. 

This paper utilizes econometric techniques to ask: what effect has the California Marine Life Protection Act had on fish densities in the Channel Islands National Marine Sanctuary? The Marine Life Protection Act (MLPA) created a network of no-take marine protected areas (MPAs) in the Channel Islands (CI) in 2003. We propose to use a database of visual fish abundance surveys collected in the CIs since 1999 to assess what effect the MLPA has had on commercially fished and unfished species throughout the Islands. 

At its face this question may not appear particularly novel. The concept itself is rather obvious: Stopping fishing in an area should increase the abundance of species that used to be fished inside that area. Many studies have documented increases in numbers, biomass, species richness, and other metrics inside the borders of protected areas [@Lester2009; @Halpern2003], though it should be noted that these results are mostly correlational. We propose two novel extensions. First, we utilize a difference-in-difference technique to attempt to assign a causal effect to the MLPA. Second, we extend our analysis outside the borders of the MPAs, to isolate the effect of the MLPA on the Channel Islands region as a whole. 

In addition, the MLPA MPAs were designed in with the goal of achieving promoting conservation while supporting livelihoods. In addition to the review process, models were used to consider the trade-offs and outcomes for conservation and fishing of alternate MPA network designs (though these models were not explicitly incorporated into the planning process) [@Rassweiler2012 ; @Costello2010]. Empirical analysis such as this this paper allow us to begin evaluating to what extent these design objectives of the MLPA are being realized. 

## Methods

We model the effect of the MLPA on densities in the Channel Islands using a Bayesian hierarchical delta model. Below we describe the data, model construction, posterior probability distribution construction, and model fitting.

### MLPA

The MLPA was enacted in 1999, with the goal of creating a network of MPAs along the coast of California. Due to political and scientific constraints widespread implementation did not begin until 2003.  However some MPAs in the Channel Islands region of the south coast date back to 1978. For the south coast sites then, the MPAs have been in place for over a decade, allowing us to begin to ask to what extent they have achieved their stated objectives [see Hamilton et al -@Hamilton2010 for a description of the bio-geography of the sites]

Caselle et al [-@Caselle2015] provides a summary of trends in fish biomass observed in the Channel Islands following the implementation of the MLPA. They report that some species show increases in biomass densities since 2002, with faster rates of increase for some fished species, as compared to unfished species. However, these trends are highly variable among species and locations. Starr et al. [-@Starr2015] found similar results in the Central Coast MLPA region.

Caselle et al [-@Caselle2015] provides an excellent basis for understanding observed changes in the fish populations of the Channel Islands following the implementation of the network of MLPA reserves in 2003. However, we have a strong interest in understanding not just correlational relationships between the MLPA and observed conservation and fishery impacts, but the actual causal effect of the MLPA. The MLPA was enacted with a specific hypothesis in mind: creating a network of MPAs will rebuild fished populations inside and outside of the reserves. It is critical then that we go back and attempt to measure whether the policy caused its intended effect, both to assess the performance of the MLPA and to help guide the broader use of MPAs as policy.

### Data

We utilize a data set described by Caselle et al. [-@Caselle2015] in our model. The data used here span the years `r min(dat$year)` to `r max(dat$year)`, covering `r length(unique(dat$site))` throughout the Islands and including over 90 species. The dependent variable used in this analysis are densities, expressed in tons per hectare, of fish per site-side (the location of a transect within a broader site). Density data were processed and provided by Dr. Jenn Caselle.  The resolution of the data is at the level of mean density of a species seen at a given site-side in a year. We use these data as our metric of fish density in order to provide comparable results to Caselle et al. [-@Caselle2015]. A wide variety of covariates are available to test the effects of the MLPA, including water temperature, visibility, surge, kelp cover, along with life history attributes such as the length, size at maturity, and trophic niche of surveyed species.

We performed a series of filtering steps to prepare the data for our analysis. Entries missing biomass densities were omitted. We also omit all entries from 1999, due to concerns about the reliability of the data from that year (survey protocols change substantially between 1999 and 2000). We omit transect sites that have not been consistently surveyed for more than two years. At each site, we omit all species that have never been observed at that site. This removes for example time series composed of zero densities of warm tropical species at the northern most CI (San Miguel). We also do not want to include rarely observed species, as their presence or absence is more likely due to observer error or transitory events than true indices of abundance. As such, we select the top 75th percentile by total observations of species for inclusion in the model. Lastly we only include entries that have all required data to run each of the candidate regressions, to ensure each run uses the same data and facilitate model comparison.

The resulting database used in the regression contain `r dim(dat)[1]` observations including `r length(unique(dat$site))` sites, `r length(unique(dat$species))` species, from the years `r min(dat$year)` to `r max(dat$year)`. 


### Identification strategy

We propose to use a difference-in-difference (DiD) estimator to determine the causal effect of the MLPA. The principal challenge of identifying causality in settings such as the MLPA is the lack of a clearly designed experiment. A more ideal MPA design strategy from the perspective of identifying causality would have been to geoengineer a few perfect replicas of the Channel Islands and randomly assign and place MPAs in some of them. Unfortunately this is not possible. Seeing as the MLPA  is not a true (or even close to true) experiment, simply looking at densities before and after the MLPA is not sufficient to identify causality. Changes could be attributable to concurrent shifts in environmental conditions, changes in fisheries management, placement of MPAs in locations that were increasing or decreasing in density pre MLPA, or a whole host of other confounding factors.

The DiD estimator allows us to isolate causality by controlling for time-invariant differences among groups before and after a treatment. Consider an outcome of interest *Z* measured at two sites *s*, one of which (*t*) is exposed to a treatment in year *Y*,  and another *c* which is not. The DiD estimator is then

$$\beta = (Z_{s = t,y{\geq}Y} - Z_{s = t,y<Y}) - (Z_{s = c,y{\geq}Y} - Z_{s = c,y<Y}) $$

  and it can be shown algebraically that time-invariant differences between *t* and *c* that affect *Z* drop out of the equation. This allows us in theory to isolate the causal effect of the treatment.

This formulation can be generalized to a regression estimator of the form

$$ \hat{Z_{i,y,s}} = \beta_{0} + \beta_{1}T_{i,y} + {\beta_{2}G_{i,s}}
+ \beta_{3}T_{i,y}G_{i,g} + \beta{...} $$


  where *T* and *G* are fixed effects indicating whether the treatment has occurred occurred in year *y* and whether the site *s* is treated, respectively. the key DiD estimator itself then is $\beta_{1}$: the effect of the treatment on the treated. Additional covariates can be included as needed to improve the fit of the model, control for variables that may not be constant over time, or that may vary below the group level.

With this model in mind, we can turn to considering our "experiment" for the DiD estimator. One strategy might be to consider sites that eventually become MPAs as the "treatment" group, and the other sites the "controls". However this poses two problems for us. First, "treatment" group data are not available pre treatment, so we have no way to calculate "difference" for this group. Second, even if we had these data, through a site-level treatment effect we would be treating each site as independent, walled off units that are treated or untreated by an MPA. While this may be acceptable if we want to consider the effects of the MLPA inside the borders of the MPA, we are interested in the effects of the MLPA across the Channel Islands.

For these two reason, we use whether or not a given species is targeted by fishing, commercially or recreational, in Southern California. Under this experimental structure, the application of the MLPA can be thought of as an exogenous shock to the fish species, some of which were fished and some of which were unfished. While it is certainly true that MPAs may have been applied in sites with higher (or lower) concentrations of fished species, at the level of the Channel Islands species certainly could not themselves influence the creation of the MLPA, or select whether or not to be in the Islands at all. Therefore, the application of the MLPA on fished or unfished groups serves as a rough approximation of an exogenous shock to the species living in the Channel Islands. Examining the data, we see a relatively even distribution of the percentage of species observed at a site targeted by fishing, overall 35% targeted in non-MPA sites and 36% targeted in MPAs (Fig.1). 

```{r dist_fished , fig.cap='Percentage of species targeted by fishing at each site-side'}


perc_targeted_plot <- reg_data %>%
  group_by(site_side) %>%
  summarize(perc_targeted = mean(targeted == 'Targeted'), MPA = unique(eventual_mpa)) %>%
  ungroup() %>%
  mutate(factor_site_side = as.factor(site_side)) %>%
  ggplot(aes(reorder(factor_site_side,perc_targeted), perc_targeted,fill= factor(MPA) )) +
  geom_bar(stat = 'identity', position = 'dodge') +
  scale_y_continuous(labels = percent) +
  scale_fill_discrete(name = 'MPA') + 
  xlab('Site Side') +
  ylab("% of Species Targeted") +
  coord_flip() +
  plot_theme+
  theme(axis.text.y = element_text(size = 4), axis.title.y = element_blank())

 perc_targeted_summary<- reg_data %>%
  group_by(site_side) %>%
  summarize(perc_targeted = mean(targeted == 'Targeted'), MPA = unique(eventual_mpa)) %>%
  group_by(MPA) %>%
  summarize(mean_perc_targeted = mean(perc_targeted))

perc_targeted_plot

```

### Model

Our dependent variable is log(tons/hectares): *d*. We choose this form since by logging the dependent variable, the coefficients of the independent variables become slightly simpler to interpret in this context. The coefficients of a log-linear regression roughly correspond to a percent change in the dependent variable per unit marginal change in the independent variable. In other words, it is easier to interpret the significant of a coefficient of 0.2 when it corresponds to a marginal effect of 20%, than a marginal increase of 0.2 in raw densities.

The next step to consider the the type of model to be used. Starting from the most basic model, we could consider an ordinary least squares (OLS) regression. We can assume that the log densities are normally distributed, since densities and CPUEs are often log-normally distributed and if so the log densities are normally distributed. OLS may then  be a candidate since we are working with normally distributed data.

However, the data contain a large amount of zeros at the species-site/side-year resolution (Fig.2). This is a common problem in many density or catch-per-unit effort style data sets. The large numbers of zeros means that we cannot simply fit an OLS regression to this data set. Instead we need to account for the zeros in the data. The standard econometric technique for continuous zero-truncated data, as we have here, is a Tobit model. The Tobit model works through data augmentation to simulate the dependent variables that we might observe if they could fall below zero. It can then be shown that the likelihood of the model conditional on the augmented data is proportional to the likelihood of the model conditional on the real data, which we cannot obtain directly.

```{r zeros,fig.cap='Histogram of mean biomass densities in the Channel Islands database. Zero values had a small constant added to appear in log space'}
dense_hist <- reg_data %>%
  ggplot(aes(log_density)) + 
  geom_histogram(color = 'black',fill = 'steelblue2') +
  plot_theme+
  xlab('Log Density (tons/hectare)') + 
  ylab('Count')

dense_hist
```

The Tobit model is not feasible for this analysis though. The Tobit model requires normality in the data. A prime candidate for a Tobit model might be hours of work. Workers cannot work negative hours (unless you count particularly unproductive graduate students), and we can measure hours continuously (e.g 0.01 hours). If we plot a histogram of hours worked we can image it appearing as a truncated-normal distribution, and we can imagine what the left-hand tail of that distribution would look like if it were un-truncated. The MLPA density data does not fit this description; rather, there appear to be two processes, one dictating whether or not a density is greater than zero, and then conditional on being greater than zero, a distribution of observed densities. 

Given this observation, we instead use a hurdle or delta modeling approach. Under this model, we consider the data two have two stages. First, a given observation must pass a "hurdle" of being seen or not (having *d* >0) with some probability *p*. Under this approach, the data has to cross a "hurdle", in which we model the likelihood of a given observation being greater than 0, and then the likelihood of the positive density data conditional on the likelihood of being greater than 0. Following Babcock & McAllister [-@Babcock2002], we can break the likelihood into two components, a binomial process modeling the likelihood of the observed densities being greater than 0 through a logit process, and a normal likelihood for the distribution of the log-transformed densities.


We consider the logit portion of the hurdle first. For a given observation at the species(*f*)-site/side(*s*)-year(*y*) level, we can model the probability of that observation being greater than 0 through a logit model

$$p_{f,s,y} = \frac{e^{\gamma_{f,s,y}}}{1+e^{\gamma_{f,s,y}}}$$


  where we model $\gamma$ as a linear function of covariates selected to explain the probability of observing any fish at all

$$\hat{\gamma_{f,s,y}} = \tau_{1}fished_{f} + \tau_{2}YearsMLPAMpas_{s,y} + \tau_{3}FxM{f,s,y} + ...$$
 $$ \sum\tau_{4}trophic_{f} + \tau_{5}linf_{f}  + \tau_{7}temp_{s,y} +
  \tau_{7}vis_{s,y}  + \tau_{8}$$

*** Add year fixed effects

  We include the DiD estimator within the logit portion of the model to estimate the effect of the MLPA on the probability of zero-density observations.

For the observations with *d* > 0, we model the expected density as

$$ \hat{d_{f,s,y}} = \beta_{1}fished_{f} + \beta_{2}YearsMLPAMpas_{s,y} + \beta_{3}FxM{f,s,y} +  \sum\beta_{4}rYeasr_{y} + 
  \sum\beta_{5}region_{s} + \sum\beta_{6}trophic_{f} + ... $$

  $$\beta_{7}linf_{f} + \beta_{8}vbk_{f} + \beta_{9}temp_{s,y} +
  \beta_{10}vis_{s,y} + $$

  $$ \beta_{11}templag1_{s,y} + \beta_{12}templag2_{s,y} + \beta_{13}templag3_{s,y} +
  \beta_{14}templag4_{s,y} + \beta_{15} $$


### Likelihoods


  For the logit component of the model we can tally the number of candidate transects *n* and the number of transects with positive densities *w* that comprised that density estimate. This translates to a binomial process where the with a probability density given by. However ar this time we do not have the component transect data, so we have to assume that each observation comes from one event, meaning that *n* is one and *w* can be zero or one.

$$ll^{l}_{f,s,y} = log(\left(
    \begin{array}{c}
      n_{f,s,y} \\
      o_{f,s,y}
    \end{array}
  \right) p_{f,s,y}^{w_{s,f,y}}(1-p_{f,s,y})^{n_{f,s,y}-o_{f,s,y}})$$


  where *p* is the estimated probability of the the number of positive densities and *ll* is the log likelihood of a given observation for logit *l*, or density *d*, portion of the hurdle model. 

  For the observations with *d*>0, the we assume a normal likelihood with a density function of 
  
  $$ll^{d}_{f,s,y}=log(\frac{1}{\sqrt{2{\pi}{\sigma}}}e^{ \frac{ (\hat{d_{f,s,y}} - d_{f,s,y})^{2} }{2} })$$
  
### Priors

We construct a series of hierarchical priors to account for clustering in the data. All parameters not listed here are assumed to have uniform priors. We model the year-term fixed effects as originating from a common normal prior

Year~y~ ~N(0,$\sigma^{y}$)

where $\sigma^{y}$ is modeled through the uninformative hyperprior

$\sigma^{y}$ ~gamma(2,0.5)

The year coefficients for the binomial portion of the model have priors constructed in the same way.

Year~y~^p^ ~ N(0,$\sigma^{y,b}$)

$\sigma^{y,b}$ ~ gamma(2,0.5)

We also assume that the prior on the regional fixed effects is distributed normal per
Region~r~ ~ N(0,$\sigma^{r}$)

with hyperprior
$\sigma^{r}$ ~ gamma(2,0.5)

Lastly the prior on the standard deviation of the densities $\sigma$ is distributed

$\sigma$ ~ gamma(2,0.5)

### MCMC

We used the LaplacesDemon package in *R* [@RCoreTeam2015] to fit our hierarchical Bayesian delta model. We ran ten million iterations, discarded the first five million, and selected every 5000th remaining sample to obtain our final thinned chain of `r dim(processed_demon$thinned_post)[1]` draws from the posterior distribution. LaplacesDemon was used to access the "Reversible Jump" option, which as subsequently found to be unfeasible for this model. Future applications of this model will be transferred to run in JAGS.

## Results

### Diagnostics

Note that coefficients marked by "bi." are the coefficients from the logit portion of the hurdle model. The DiD estimators are "fished" indicating whether a given species is fished, "years_mlpa_mpas" which indicates the number of years in which an MLPA generated MPA has been in the region, and the interaction of those two terms is marked by "fished_x_yearsmlpa".

The DiD estimator depends critically on the assumption that the trends in the outcome of interest, in this case fish densities, are the same between the treated and untreated groups pre-treatment. In essence, the DiD estimator assumes that post treatment the untreated group should serve as a proxy for how the fish densities in the treated group would have evolved had they been untreated. In this example, our hypothesis is that the fished and unfished groups are both responding in the same manner to the same regional environmental trends, even if the raw density values between the groups are different. 

We can analyze trends in densities between the two groups pre-MLPA as an initial check of the validity of this assumption (Fig.3). Visually inspecting the trends, we see that while the fished and unfished groups do not have matching trends, they do appear to be loosely reacting to the same regional trends. Both groups show declining trends in density pre-MLPA, and increases post-MLPA. This suggests that for this phase of the analysis using unfished species as a "control" for the theoretical trajectory of fished densities post-MLPA is not entirely unreasonable. However more quantitative tests should be applied at a later date. Specifically, we will run a "placebo" test in which we test whether slopes are significantly different between the two groups before and after a "placebo" start date of the MLPA, such as 2001. In theory for the DiD estimator to be valid in this context we should fail to reject the hypothesis that both groups have identical slopes pre and post placebo.  

```{r denplot, fig.cap= 'Mean log densities of fish and unfished species over time. Dashed line shows implementation of MLPA reserve in the CIs'}
density.by.year_plot <-
  ggplot(subset(dat), aes(factor(year),log_density, fill = factor(targeted))) +
  geom_boxplot(aes(fill = factor(targeted))) +
  plot_theme 

did_trend <- dat %>%
#   subset(year<=2005) %>%
  group_by(fished,year) %>%
  summarize(mean_mean_density = mean(log_density)) %>%
  ungroup() %>%
  mutate(fished = fished == 1) %>%
  ggplot(aes(year,mean_mean_density, color = factor(fished))) + 
  scale_color_manual(name = 'Fished', values = c('orange','forestgreen')) + 
  geom_line(size = 2) + 
  geom_vline(aes(xintercept = 2003), linetype = 'longdash') + 
  xlab('Year') + 
  ylab('Mean Log Density') + 
  plot_theme

did_trend
```

Moving to our MCMC diagnostics, we broadly see evidence that substantially more runs are likely to be needed in order to achieve convergence. The acceptance rate over our 10e6 runs was 0.34. Examining our final thinned chain, we see that many of our coefficients fail the Geweke diagnostic, meaning that the means of the initial and final portions of the chain are significantly different than each other, indicating non-convergence of the thinned chain (Fig.4). Among the DiD estimators, the "fished" coefficient fails the Geweke statistic for both the logit and log portions of the hurdle model. The other DiD estimators pass, but marginally.

```{r geweke, fig.cap='Geweke diagnostics of MCMC runs'}
plots$gweke_plot + 
  theme(axis.text.y = element_text(size = 8))
```

We can further examine the convergence of the density DiD estimators by examining the partial-chain comparisons (Fig.5) and Heidelberger-Welsh statistics for the DiD estimator parameters. The "fished" coefficient passes the Heidelberger-Welsh test, but the interaction term and the "years_mlpa_mpas" did not. It is somewhat unclear why the interaction term fails the test given the partial chain comparison (Fig.5). Considering the DiD estimators for the logit component of the model, only the interaction term passes the Heidelberger-Welsh test.

```{r partial_chain, fig.cap='Partial chain comparisson of the density linear regression'}


of_interest <- as.data.frame(processed_demon$thinned_post) %>%
  select(fished,years_mlpa_mpas,fished_x_yearsmlpa) 

heidel <- heidel.diag(mcmc(of_interest))

bi_of_interest <- as.data.frame(processed_demon$thinned_post) %>%
  select(bi.fished,bi.years_mlpa_mpas,bi.fished_x_yearsmlpa) 

bi.heidel <- heidel.diag(mcmc(bi_of_interest))

partial_of_interest <- ggs_compare_partial(ggs(mcmc(of_interest))) + 
  plot_theme

acf_of_interest <- ggs_autocorrelation(ggs(mcmc(of_interest))) + 
  plot_theme

bi_partial_of_interest <- ggs_compare_partial(ggs(mcmc(bi_of_interest))) + 
  plot_theme

all_of_interest <- ggs_compare_partial(ggs(mcmc(cbind(of_interest,bi_of_interest)))) + 
  plot_theme

all_of_interest + theme(text = element_text(size = 8))

```


We also see that substantial auto-correlation remains in the samples, evening after thinning the post burn-in 5e6 iterations down to 1,000. Observing the lag-1 auto-correlation of all `r dim(processed_demon$thinned_post)[2]` parameters, we see that a substantial number of parameters have very high lag-1 autocorrelation, including near perfect autocorrelation in for many variables (Fig.6).


```{r acf, fig.cap='Histogram of lag-1 autocorrelations'}
plots$acf_hist_plot 
```

We also see that due to this auto-correlation issues, the effective sample size of the vast majority of our samples are incredibly small. This further supports that so far many of the coefficients of the model are very poorly estimated (Fig.7).

```{r ess, fig.cap='Effective sample size of model coefficients'}
plots$eff_sample_plot + 
    theme(axis.text.y = element_text(size = 8))

```

We see some explanation for this behavior by examining the cross-correlation plot of the estimated coefficients. Specifically, we see very high correlation among the year effects in both portions of the hurdle model.We also strong correlation between the year terms and the "years_mlpa_mpa" portion of the DiD model. All this suggests that we may need to more directly account for the covariance among the coefficients (Fig.8).

```{r crosscorr, fig.cap='Cross-correlations of model coefficients. bi indicates components used the the logit portion of the hurdle model'}

ggs_crosscorrelation(ggs(mcmc(processed_demon$thinned_post))) + 
      theme(axis.text = element_text(size = 5)) + 
  scale_fill_gradient2(low = ('orange'),high = ('green'),mid = 'white',midpoint = 0,name = 'Scaled Correlation', limits = c(-1,1))
```

Moving to the posterior predictives, we compared test statistics (max, min, mean, and standard deviation) drawn from the posterior predictive distribution, to the test statistics from the observed data. We constrain this portion of the analysis to the positive observed densities. 

We see that the observed test statistics fall within the 95% credibility interval of the test statistics generated from the posterior predictive for all statistics except the max (Fig.9). This indicates that the model is predicting more instances of high densities than are supported by the data. We also see that the model is overall a relatively poor predictor of densities, with a pseudo-R^2^ of ~0.14 (Fig.10). This bias is less a concern for this model since we are more concerned with the robustness of the DiD estimators than the predictive ability, but is worth noting. 

```{r post_predict, fig.cap='Posterior predictive test statistics. Black lines are 95% CI, red dashed line is the observed value', cache = T}

b <- 2 
#load me now

den_post_preds <- processed_demon$post_pred$posterior %>%
  subset(obs_log_density > min(obs_log_density)) 

post_preds_check <- den_post_preds %>%
  group_by(observation) %>%
  summarize(dat_in_post = unique(obs_log_density)<=quantile(post_predict,.975) & unique(obs_log_density)>=quantile(post_predict,.025))

samps <- sample(unique(den_post_preds$observation), 25)

check <- subset(den_post_preds, observation %in% samps) %>%
  ggplot(aes(post_predict)) + 
  geom_histogram() + 
  geom_vline(aes(xintercept = quantile(post_predict,c(0.025,0.975)))) + 
  geom_vline(aes(xintercept = (obs_log_density)), linetype = 'longdash',color = 'red') + 
  facet_wrap(~observation) + 
  plot_theme


  post_summary <- den_post_preds %>%
    group_by(chain) %>%
    summarize(min_pp = min(post_predict), max_pp = max(post_predict), mean_pp = mean(post_predict),
              sd_pp = sd(post_predict), min_real = min(obs_log_density), max_real = max(obs_log_density), mean_real = mean(obs_log_density),
              sd_real = sd(obs_log_density))
  
  reals <- gather(post_summary,'statistic','real',min_real:sd_real) %>%
    mutate(stat_name = gsub('\\_.*', '', statistic))
  
  post_summary_plot <- post_summary %>%
    gather('statistic','value',min_pp:sd_pp) %>%
    group_by(statistic) %>%
    mutate(lower95 = quantile(value,0.025), upper95 = quantile(value,0.975)) %>%
    ungroup() %>%
    mutate(stat_name = gsub('\\_.*', '', statistic))%>%
    left_join(select(reals,stat_name,real), by = 'stat_name') %>%
    #group_by(statistic) %>%
    ggplot(aes(value)) + 
    geom_histogram() + 
    geom_vline(aes(xintercept = lower95)) + 
    geom_vline(aes(xintercept = upper95)) + 
    geom_vline(aes(xintercept = real), linetype = 'longdash', color = 'red') + 
    facet_wrap(~stat_name, scales = 'free_x') + 
    plot_theme + 
    xlab('Value') + 
    ylab('Count')

post_summary_plot

```

```{r obs_v_pred, fig.cap='Observed log densities (for observed densities) against median posterior predictive log density against'}

plots$post_pred_plot

```

The preceding MCMC diagnostics provide evidence that we will need to perform substantially more iterations than my computer and timeline can handle at this moment. Since we did not achieve satisfactory convergence with one chain, it was not worthwhile to explore parallel chains to further verify the lack of convergence. 

Beyond the MCMC diagnostics, we should consider standard regression diagnostics to understand the validity of our coefficients. For now we focus on the density model. Our assumption is that the log-densities are normally distributed. Looking at a normal quantile-quantile plot of the residuals of the density model, we see that our assumption of normality appears justified (Fig.11).

```{r qqnorm, fig.cap='Normal quantile-quantile plot of observed vs theoretical residuals of positive densities. Black solid line is the 1:1 line, red dashed line a line of best fit' }

plots$qq_plot

```

As we explore the development of this model, we should also consider potential violations of the *iid* assumptions as we consider how best to address the nested nature of the data. Looking broadly at the residuals, we do not see evidence of model misspecification, though there is some evidence of heteroskedasticity (Fig.12)

```{r model_spes, fig.cap='Residuals as a function of predicted density'}

plots$misspec_plot

```

We can now turn to the nested nature of the data. We know that the data are clustered by year, site-side, and species. Looking at the residuals by time, it appears that the inclusion of year fixed effects and lagged temperature effects were sufficient to remove heteroskedasticity and autocorrelation in the residuals over time (Fig.13)

```{r, fig.cap = 'Boxplot of residuals by time. Triangles indicate mean of residuals'}
plots$resids_by_time_plot
```

Turning to the regional effects, we would expect there to be correlation in the residuals among nearby sites. We do not include site-specific fixed effects as the model quickly becomes over-fit at that point. We do include region fixed effects with a shared hyperprior in an effort to control for spatial correlation in densities. We see that while there is clear correlation in the residuals, it appears that the region effects were able to substantially account for this (Fig.14). 

```{r, fig.cap = 'Boxplots of residuals by site.  Triangles indicate mean of residuals. Sites are ordered by proximity'}

plots$resids_by_site_plot
```

Lastly, we can consider the residuals by species. We can assume that the life history characteristics included in the model would be best represented by a multivariate normal distribution, since parameters such as *L~inf~* and *k* are correlated. However we have not yet accounted for this, partly to reduce the complexity of the model at this stage. Examining the residuals by species group, we can see that there is clear within-species correlation in the residuals, though there does not appear to be within tropic-group correlation (Fig.15). This indicates that while the degree of spatial correlation does not appear severe enough to warrant more complex modeling of spatial correlations, we will need to address the within-species correlations. 

```{r, fig.cap = 'Boxplots of residuals by species. Triangles indicate mean of residuals'}

plots$resids_by_species_plot
```

### Estimated Effects

Having poured over diagnostics, we can now consider the actual estimated DiD coefficients (keeping in mind that diagnostics suggest that we need many more runs and improved accounting for species correlations; see SI for full posterior distributions)(Fig.16). We consider the DiD estimators for both the logit and log density components of the delta model. Looking first at the density model, we see that the median estimated coefficient of the "fished" group is
`r round(median(thinned_post$fished),2)` (95% credibility interval (CI) of `r round(quantile(thinned_post$fished,.025),2)` - `r round(quantile(thinned_post$fished,.975),2)`), indicating that all else equal fished species have ~60% higher densities than unfished. Interestingly the coefficient on the number of years post-MLPA (aka 2003 for the Channel Islands) was highly negative, with a median value of `r round(median(thinned_post$years_mlpa_mpas),2)` (95% CI of `r round(quantile(thinned_post$years_mlpa_mpas,.025),2)` - `r round(quantile(thinned_post$years_mlpa_mpas,.975),2)`. Lastly the "treatment on the treated" coefficient of the interaction between being fished and the number of years post-MLPA was not significantly different than 0, with a median value of `r round(median(thinned_post$fished_x_yearsmlpa),2)` (95% CI of `r round(quantile(thinned_post$fished_x_yearsmlpa,.025),2)` - `r round(quantile(thinned_post$fished_x_yearsmlpa,.975),2)`. This indicates that the model cannot detect a significant effect of the MLPA on fished species at the regional level, and in fact suggests that densities of unfished species decreased post MLPA.

```{r result, fig.cap='DiD estimators for the log density regression predicting densites of fish > 0'}

plots$outs_of_interest_plot + theme(strip.text.y = element_text(size = 9))

```

Looking at the logit component of the model, we see that whether or not a species is fished has no significant effect on the probability of observing a school (Fig.17). Interestingly the DiD estimators of the remaining terms are perhaps more of what might be expected, with the "Years MLPA" and interaction term significantly increasing the probability of a given observed density being > 0. This suggests that the MLPA has decreased the probability of "zero" observations of fished species. 

```{r result2, fig.cap='DiD estimators for the logit regression predicting probability of densities > 0'}

plots$outs_of_interest_binomial_plot + theme(strip.text.y = element_text(size = 9))
```

```{r sigmas, fig.cap= 'Posterior distributions of sigma parameters'}

plots$outs_of_interest_sigma + theme(strip.text.y = element_text(size = 9))

```


Lastly, we can consider this process as roughly analogous to a CPUE standardization in the "delta" manner summarized by Maunder & Punt [-@Maunder2004]. From that perspective, the coefficients of the year fixed effects in the density model (which are scaled relative to the year 2000) being the standardized indices of abundance (Fig.19). From this perspective, we see an interesting (and troublesome) trend of increasing densities post 2003, coincidentally the same year as the MLPA. 

```{r year_trend,fig.cap='Boxplots of posteriors of estimated year fixed effects coefficients. Values are relative to the year 2000'}
plots$year_trend_plot + theme(axis.text.x = element_text(size = 8))
```

## Discussion

Somewhat unsurprisingly, this project became much more complicated than expected. However this analysis has helped guide the future development of this project and has produced some interesting insights already. 

Our initial goal was to attempt to detect the causal effect of the MLPA on fish densities throughout the Channel Islands region. Preliminary results indicate that:

  1. All else equal, the model identifies the contribution of the MLPA as having reduced densities of unfished species, with no detectable marginal effect on the densities fished species.
  2. The model suggests that the MLPA has reduced the probability of a given observation being zero. This could be attributed to increases in abundance, or potentially changes in sampling ability


This in and of itself is a novel finding. Caselle et al. [-@Caselle2015] reports a significant increase in densities of fished species inside the MPAs post MLPA. Ignoring for a moment the question of causality, at the Channel Islands regional level we are unable to detect a significant impact of the MLPA on the densities of fished species, as compared to unfished.  

This is clearly an initial investigation and it remains to be seen if these results hold. There are several key issues that need to be investigated. First examining Fig.19, we see that the trend in abundances, as measured by the coefficients of the year fixed effects, shows an general increase beginning in and continuing since 2003, the year in which the MLPA MPAs were implemented in the Channel Islands. Given that we only have data from the Channel Islands at this point, we have no "contrast" in the number of years protected by the MLPA: all regions start in 2003. 

As such, it is very difficult for the model to separate out the effects of the MLPA from the year fixed effects. We can verify this by examining Fig.8, which shows that year effects and the DiD estimators related to years protected by the MLPA are highly correlated. This suggests that obtaining robust estimates of the individual coefficients of each term may be challenging. Data from the south and central coast, which have different start-dates for their MLPA enacted MPAs, should help provide much clearer contrast in the data to separate out the effects of the MLPA from time-trends. 

Further consideration of the hierarchical nature of the data also warrants consideration. While our results show that we have accounted for spatial and temporal correlations reasonably well, we have not properly accounted for the within-species nesting of the data. However, we would expect that heteroskedasticity at the species level would not bias our results, but would be more likely to influence the distribution around the expected value of the coefficients.

As some support for the notion that we may not need to be as concerned with the nested nature of the data in order to obtain expected values of coefficients (or the lack of convergence at this point), we compared the estimates obtained from the log density portion of the Bayesian regression described here to an ordinary least squares estimate of the coefficients for the same parameters. We see that by and large, and very depressingly, the two methods yield nearly identical results for most of the coefficients in the model (Fig.20).


So, this suggests that inclusion our hierarchical priors is not substantially influencing our point estimates of coefficients. It also suggests that while our MCMC has not converged, we would likely not expect its final converged values to differ substantially.  It also calls into question the next phase of this analysis, seeing as the frequentist version takes three lines of code and runs in less than one second, while the Bayesian approach is currently running for nine hours on the NCEAS server. Once we extend this analysis to multiple regions, or attempt to link the model to a more explicit model of the data collection process, or link to model estimates of spatial fishing patterns, the Bayesian framework may still prove useful. 


```{r frequentist, fig.cap='Comparison of posterior distributions of estimated coefficients from bayesian (boxplots) and point estimated from linear OLS (red points)'}

  pos_vars <- c('fished','years_mlpa_mpas','fished_x_yearsmlpa','factor_year',
                'region','linf','vbk','trophic.group','na_temp','na_vis', 'mean_temp_lag1', 'mean_temp_lag2','mean_temp_lag3',
                'mean_temp_lag4', 'eventual_mpa')

  reg_dat <- data.frame(reg_results$Data$dep_var,reg_results$Data$den_reg_mat)

  freak_reg <- tidy(lm(log_density ~. - 1, data = subset(reg_dat, log_density >min(log_density)))) %>%
  rename(coefficient = term, freq_estimate = estimate)
  
  comp <- thinned_post %>%
    gather('coefficient','estimate', convert = T) %>%
    subset(!grepl('bi.',coefficient) & !grepl('sigma',coefficient)) %>%
    left_join(freak_reg, by = 'coefficient') %>%
    ggplot(aes(factor(coefficient),estimate)) + 
    geom_boxplot() + 
    geom_point(aes(factor(coefficient),freq_estimate), shape = 16, color = 'red') + 
    plot_theme  + 
    theme(axis.text = element_text(size = 7), 
          axis.title.y = element_blank()) + 
    ylab('Coefficient') + 
    geom_hline(aes(yintercept = 0), linetype = 'longdash', size = 1)+ 
    coord_flip() 
  
  comp


```

From the perspective of causality, the inclusion of the DiD estimator gives us greater confidence that we are estimating the causal effect of the MLPA, as opposed to simple inside-outside or fished-unfished comparisons. In addition, by including a representative suite of plausible covariates we likely improve the point estimates of the coefficients, since omission of factors such as the life history of species or time trends are highly likely to result in omitted variable bias. 

Substantial work remains before we can be certain that we have reasonable identification of the causal effect of the MLPA. We have `r length(unique(dat$species))` different species in our data, representing potential treatment "groups" in our model, analogous to `r length(unique(dat$species))` different cities, some of which receive a treatment and some that do not. The DiD estimator works best with >30 groups, a threshold we have exceeded. However, given the lack of strong convergence of the current model, we have not extensively explored alternative model configurations. A strong estimator should be relatively insensitive to reasonable model configurations. Preliminary analysis suggest that the effect of the MLPA shifts in response to inclusion of covariates, which suggests that we need to carefully consider model selection (and potential Bayesian model averaging) in our subsequent analyses. 

Regardless of parameterization, the DiD estimator should become more robust once we can add additional regions and obtain contrast in the year of MPA implementation. Given that the data are noisy though we should not put all our eggs in one basket. One of the next steps is to explore fitting the same model using propensity scores based on species traits. This provides us another avenue towards identification, which we can compare to the DiD estimator. 


As a final consideration, it is worth noting that this model is a very poor predictor of densities (Fig.10). This is perhaps not surprising given the relatively fine scale resolution of the data (yearly mean species level densities along a transect of 30 meters), but is still worth considering. From a general perspective, this indicates the complicated evolution of fish populations over time, which those of us (such as myself) who engage in simulation studies of MPA effects should take seriously into consideration.  

Our preliminary results do not detect a significant causal effect of the MLPA on the positive densities of fished species throughout the Channel Islands. While substantial work remains before we can hang our hat on this result, it does have one clear implication: the signal of the MLPA on regional fish densities is far from clear. While within-MPA results may show stronger contrast, we might not expect improved statistical methods to identify much clearer signals in the regional effects of the MLPA (though improved isolation of the MLPA effects and the year terms may yield dramatically different results). Given that the link between the MLPA and fish densities is relatively simpler than the link between the MLPA and fishing profits, it will be interesting to see how that next phase of the analysis, attempting to link the MLPA to economic outcomes, goes. 
  



## Works Cited
