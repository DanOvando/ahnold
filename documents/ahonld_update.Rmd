---
title: "Update on “Effects of the MLPA"
author: "Dan Ovando"
date: "11/16/2017"
output: 
  bookdown::pdf_document2: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```

```{r load-life}
rm(list = ls())
library(tidyverse)
library(sf)
library(lubridate)
library(glue)
library(hrbrthemes)
library(extrafont)
library(viridis)
library(scales)
library(stringr)
extrafont::loadfonts()

demons::load_functions('functions')

run_name <- 'Working'

run_dir <- file.path('../results', run_name)

summary_theme <- hrbrthemes::theme_ipsum(base_size = 16)

theme_set(summary_theme)

```

```{r load-data, cache = T}

load(glue("{run_dir}/abundance_indices.Rdata"))

load(glue("{run_dir}/did_models.Rdata"))

load(glue("{run_dir}/rawish_ahnold_data.Rdata"))

life_history_data <-
  read_csv('../data/VRG Fish Life History in MPA_04_08_11_12 11-Mar-2014.csv') %>%
  rename(classcode = pisco_classcode) %>%
  mutate(classcode = tolower(classcode)) %>%
  magrittr::set_colnames(., tolower(colnames(.)))


```


# Project Overview

The goal of this chapter is to answer the question: What effect did the Marine Life Protection Act (MLPA) have on the density of fished species in the Channel Islands?

We've been hunting this question for quite a while, due to a series of complications in the data and analysis. The purpose of this document is to give a high-level overview of my current results, so that we can make decisions on the next steps forward. 

To provide a high level summary:

Substantial amounts of theory and modeling work supports the idea that networks of MPAs should affect (and hopefully benefit) fish populations in the waters both inside and surrounding the MPAs, through mechanisms such as larval or adult spillover (as well as their affect on fishing behavior). However, the vast bulk of empirical work on MPAs has focused on assessing what happens inside MPAs (or inside-outside comparisons), rather than on asking what the network-wide effects of a web of MPAs is. To fill that gap, this study looks to determine what affect the network of MPAs placed in the Channel Islands in 2003 has had on the abundance of fishes throughout the Islands in the years since the implementation of the reserves. 

## Identification Strategy

We need some sort of identification strategy to isolate the causal effect of the MLPA from other factors such as environmental drivers. For now, we have selected to use fished and unfished species as as treatment/control in a difference in difference estimator. The underlying hypothesis behind this assumption is that unfished species (e.g. garibaldi) and fished species (e.g. blue rockfish) are both affected by environmental drivers such as El Niño, but only the fished species are substantially affected by the placement of MPAs. As such, we use the trends in abundance of unfished species as our control for broader environmental trends, and more or less the divergence in trends between the fished and unfished groups post-MLPA as our estimate of the causal effect of the MPAs. I will provide evidence in support of this choice later on, but obviously there are concerns with this selected strategy that bear consideration. 

Ignoring other controls for the moment then, the general model being considered is

$$ Abundance_{s,y} = Fished_{s} + PostMLPA_{y} + Fished_{s}*PostMLPA_{y}$$

Where *s* is species *s*, *y* is year, and abundance is derived from densities (as will be explained later). 

This seems simple enough, so why aren't we done? Well, as always the devil is in the details, and below I'm going to walk us through those details and that our decisions related to them mean for our results. 

# Method Choices

There are three basic groups of problems that we need to tackle here, and I'll do my best to briefly outline the choices that are available and how I've addressed them. I have run the model over every factorial combination of these choices, and will present high level summaries of the results in the "results" section.  

## What data to use

All the data available to us are visual survey scuba transects performed throughout the Channel Islands, in which divers ID, count, and in some cases estimate lengths, for observed fish species.However, there are three choices of which of these data to actually use. 

The first is the processed density data utilized in @Caselle2015. These data come from PISCO, and have already been converted from raw fish observations to biomass densities, and have the advantage of having been vetted by a team who are experts in the local system and in the details of the data collection process. 

The second is the raw PISCO data. These data need to be converted from raw observations of species-numbers-lengths to biomasses, which requires a series of QAQC steps, but is relatively straightforward. Working at this level provides access to finer-scale data such as the names of indivudal observers, which we can then control for in our model. For now, this is my preferred method of analysis. 

The third is a similar but separate database, collected through the Kelp Forest Monitoring (GFM) program of the Channel Islands National Park. The methods are similar, but the data from the KFM program goes back earlier than the PISCO data. However, length estimates are only available for a small subset of years in the KFM data, as such densities can only be measured in terms of numbers, not biomass. Therefore, the KFM data is useful to as as a check for whether we see starkly different results with different data but is likely not good for our primary results. 

Here are a few summary graphs just to given an idea of the differences in data coverage and raw densities by database. 

We can see that there are pronounced differences in both data coverage and mean abundance trends across the KFM/PISCO data, and minor differences between the manually processed PISCO data and the PISCO data utilized by @Caselle2015 (Fig.\@ref(fig:compare-raw-densities)). We also see some visual evidence that the parallel trends assumption is not ludicrous, as the fished and unfished species do appear on average to follow similar trends over time. 

```{r compare-raw-densities, fig.cap='Mean density over time for each data source. Circles indicate number of observations'}

lengths <- length_to_density_data %>% 
  filter(is.na(targeted) == F) %>% 
  group_by(targeted, factor_year) %>% 
  summarise(mean_density = mean(mean_biomass_g, na.rm = T),
            nobs = length(mean_biomass_g)) %>% 
  mutate(data_source = 'lengths converted to densities') %>% 
  ungroup() %>% 
  mutate(targeted = targeted == 'Targeted' & is.na(targeted) == F)

raws <- density_data %>% 
    filter(is.na(targeted) == F) %>% 
  group_by(targeted, factor_year) %>% 
  summarise(mean_density = mean(biomass, na.rm = T),
            nobs = length(biomass)) %>% 
    mutate(data_source = 'Caselle et al. 2015') %>% 
   ungroup() %>% 
  mutate(targeted = targeted == 1 & is.na(targeted) == F)


kfms <- kfm_data %>% 
    filter(is.na(targeted) == F) %>% 
  group_by(targeted, factor_year) %>% 
  summarise(mean_density = mean(density, na.rm = T),
            nobs = length(density)) %>% 
    mutate(data_source = 'kelp forest monitoring') %>% 
   ungroup() %>% 
  mutate(targeted = targeted == 'Targeted' & is.na(targeted) == F)

comp <- lengths %>% 
  bind_rows(raws) %>% 
  bind_rows(kfms)

comp %>% 
  ungroup() %>% 
  mutate(year = factor_year %>% as.character() %>% as.numeric()) %>% 
  group_by(data_source, targeted) %>% 
  mutate(mean_density = mean_density / max(mean_density, na.rm = T)) %>% 
  ungroup() %>% 
  ggplot(aes(year, mean_density, color = targeted)) + 
  geom_line() + 
  geom_point(aes(size = nobs),alpha = 0.5) + 
  facet_wrap(~data_source)

```

Regardless of the choice of database to use, we then need to decide on some filtration steps in the data. These aren't particularly interesting but for consistency worth noting. For every run, we only include species that have been seen at least 10 times a year every year since 2000, in order to control for rare species dropping in and out of the database, and only include observations from the main Channel Islands (ANA, SCI, SRI, SMI). 

As an additional option, after this filtering we can also consider only locations in the CIs that have been consistently sampled throughout the entire study period. 

## How to structure the higher level model

Our final goal is to estimate the coefficients of the DiD estimator. We have the data for the DiD estimator, as well as a slew of covariates that vary slightly be database, but broadly include environmental factors both local(temperature, visibility, kelp, surge) and regional (El Niño, PDO), location, life history traits, and observer characteristics. We could in theory then dump all of these variables into one regression in which we attempt to use observables to control for both environmental and observational confounders, and use the DiD estimaators to control for unobserved time-invariant differences. 

There are unfortunately (at least) two problems with this. The first is simply conceptual: the resulting model has hundreds of coefficients and so becomes somewhat unweildly to interpret and make sure that the isolated DiD estimator is doing what we think it is doing. 

The second and more substantial problem is how to deal with sampling events in which a particular fish wasn't seen. Given that we're dealing with visual transect data in a challenging environment (low vis, surge, kelp), most transects do not observe every possible fish species each transect (possible fish are defined as a species that has been observed at least once at a given island at any time in the datbase). Conditional on the list of candidate fish species, if a fish species was not observed, we then have to determine whether it was there and not seen, or whether it was just not there but could have been there. Given the challenges of visual survey data, most of the observations in our database are zeros (~`r 100*(1 - mean(length_to_density_data$any_seen, na.rm = T)) %>% round(2)`%, Fig.\@ref(fig:lhist) ). 

This is a common problem in ecological research, but presents some problems for us. Our goal is obtain our DiD estimators. We can't though just include the zeros and positive observations in the same regression, since the zeros will dominate the data and lead to all kinds of violations of our error assumptions. A tobit model could be considered, but the problem here is not truncated data, but rather a "hurdle" process in which a given group of fish at a transect have a probability of being observed, and a true density conditional on being observed. 
s
To address this in ecology, we commonly use "delta" or "hurdle" models, in which the expected density is a function of the probability of observing a density *d* greater than 0 $p(d>0)$ and the expected densidy conditional on observation $E(d|d>0)$

$$\hat{d} = p(d>0)E(d|d>0)$$

This model is fit using a logit type regression for the probability of observation, an appropriate regression for the observed densities (e.g. lognormal). 

We could include the DiD estimators inside each of the component regressions, and then bootstrap out a "net effect" term and bootstrapped standard errors as well... something to consider. The challenge there is in interpretation of the coefficients of interest. 

For now then, the path that I have taken is to break the model into a two part process

1. Estimating a "standardized" abundance trend for each species using the hurdle model - This step incorporates the zeros and attempts to control for observational biases in the probability of detection and the observer densities

2. Fitting the DiD estimator on the standardized abundance trends, controlling for environmental covariates - things that affect "actual" density besides the MPAs themselves. 


The advantage to this method is that it deals with the zeros in the data, and provides for much more interpretable model coefficients. The disadvantage is that it treats the standardized abundance trends as "data", and as such vastly underestimates the uncertainty in the model. I've coded up a fully integrated version of the model in STAN to deal with this, but it takes forever to converge so putting that on the backburner for the moment. Alternatively, we can generate monte-carlo confidence intervals from the discrete version here, but as we'll see, I think this is the least of our problems so I haven't gone down that route yet. 


```{r lhist, fig.cap = 'Histogram of log transformed densities (small number added to zeros)'}

length_to_density_data %>% 
  ggplot(aes(log(mean_biomass_g + 1e-3))) +
  geom_histogram(fill = 'steelblue2', color = 'black') + 
  labs(x = 'log density')


```

## Alternative States of the World

Along with questions on the raw mechanical methods for fitting this model, we also have to consider alternative states of the world. and model structures. 

The "states of the world" that I consider relate to the population structure of the fishes in the Channel Islands. 

- One population: Each species is made up of one population throughout the islands (each species has one abundance trend). This is consistent with a shared larval pool and some degree of adult mixing

- Island populations: Each island has its own population (each species has as many abundance trends as islands it has been observed at). This is consistent with island-level recruitment and movement

- MPA populations: "Separate" populations exist inside and outside of MPAs (each species has two abundance trends). This would be consistent with either no larval or adult movement, or larval connectivity but no adult movement (in which case in the long term we would still think of them as one population but observed biomasses change substantially due to differential fishing pressures on recruited resident populations). 


In addition to these three states, we also consider three time-scales at which the MPAs can affect observed densities. 

- Annual MPA effects: We estimate the effect of the MPAs each year, allowing them to evolve over time but holding the time effect constant for each species

- Generation-time MPA effects: We estimate the effect of the MPAs in units of "generations" protected, where generation time is defined by the age at maturiy for the species in question. This rescales the MPA effect for each species

- Survey-recruitment MPA effects: We estimate the effect of the MPAs in units of years-to-survey-recruitment, defined by the age at which a given species was first observed in the survey. 

# Null hypotheses

With all of these models, we then need to consider what the null hypothesis is that we are testing our estimated MPA effects against. The most obvious choice is 0, i.e. can we reject the null hypothesis that the MPAs had no effect on densities of fished species. 

Alternatively though, we can also specify more specific null hypotheses, derived either from literature or modeling. Literature can include specific hypotheses on the predicted affect of MPAs on fish densities based off of empirical or theoretical work. I'm going to dig into the lit and find a few of these to include. 

As an alternative, I have also developed a spatially-explicit bio-economic operation model for generating a slew of predicted densities over with and without MPAs for the species in our databse, under factorial combinations of states-of-the-world, since relatively little is known about the actual state of these species. For example, for each species we consider a range of pre-MPA populations states (overfish, underfished), a range of population structures and density dependence (high/low adult/larval movement, pre/post settlement density dependence, etc), and a range of fleet responses (constant fishing pressure, concentrated fishing pressure, ideal-free distribution, open-access dynamics), as well as a scenario where I feed in the catches reported by CDFW in the Santa Barbara Channel region, and assume the catches to be exogenous to the MPAs. I'll go into more detail on this in person, but the point of all this being that the model generates a host of predicted "mpa effects" that we can try and use our estimated model to accept or reject. E.g. while we may not be able to reject 0, maybe we can reject a very negative or very positive affect of the MPAs. 

# Early results

The factorial combination of the choices of what data, what model, and what hypotheses make for a very unweildy slew of results. For now then, I'm going to highlight some particularly interesting results to given an idea of where we stand. 

## Evidence of parallel trends

The whole "causal" side of this paper depends on the degree to which unfished species serve as an effective control for fished species. In a perfectly ideal world, both fished and unfished species are affected in the same way by environmental drivers such as El Niño, and there are no trophic interactions among species. In addition, fishing pressure would ideally be in equilibrium pre-and-post MPA, so as not to confound market-driven changes in fishing mortality with MPA driven effects. The world is not this kind, but it is instructive to think through what evidence we have of gross violations of these assumptions (aknowledging that they are of course all violated to some degree). 
For this section I am focusing on densities derived from the "raw" length-frequency observations. 

We have already looked at the raw density trends, which give some evidence of parallel trends

```{r}

lengths <- length_to_density_data %>% 
  filter(is.na(targeted) == F) %>% 
  group_by(targeted, factor_year) %>% 
  summarise(mean_density = mean(mean_biomass_g, na.rm = T),
            nobs = length(mean_biomass_g)) %>% 
  mutate(data_source = 'lengths converted to densities') %>% 
  ungroup() %>% 
  mutate(targeted = targeted == 'Targeted' & is.na(targeted) == F) %>% 
  mutate(year = as.numeric(as.character(factor_year))) %>% 
  group_by(targeted) %>% 
  mutate(mean_density = mean_density / max(mean_density))

lengths %>% 
  ggplot(aes(year, mean_density, color = targeted)) + 
  geom_line() + 
  geom_point() + 
  labs(y = 'Max Scaled Mean Density') + 
  scale_color_discrete(name = 'Fished Species?')
```

This gives us some visual evidence that the parallel trends is not on average ridicuolus. 

We can also look at cross-correlation coefficients across targeted and non-targeted species as a whole, and as individual species. We see that on average, abundances of targeted and non-targeted species included in the analysis are positively correlated with each other, though the cross-correlations of individual species can vary widely. That there is evidence for positive correlation is good for us on two fronts. First, it provides evidence for our parallel trends assumption, under a hypothesis that both groups of species are affected in the same way by the same environmental drivers. Second, if the reason that the two groups are correlated is due to inter-species interactions, the positive correlation coefficient would suggest some sort mutualism. Since the causal effect is measured from the difference between the targeted and non-targeted species, if they both go up, then the difference should be insensitive to this correlation. However, if the target and non-targeted were negatively correlated, for example through predation cycles, then an increase in targeted (predatory) species might produce a decrease in non-targeted (prey) species, hiding the MPA effect. 


```{r cor-test, fig.cap='Distribution of correlation coefficients between targeted and non-targeted species for pre-MPA, post-MPA, and all time periods. Red line indicates mean correlation coefficient'}

eg_run <-did_models %>% 
  filter(data_source == 'length_to_density',
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index',
         population_filtering == 'all',
         did_term_names == 'years-protected')



correlations <- map_df(eg_run$correlation_tests[[1]][1:3],c('estimate')) %>% 
  gather(correlation_period, cross_correlation)

significance <- map_df(eg_run$correlation_tests[[1]][1:3],c('p.value')) %>% 
    gather(correlation_period, p_value)

cis <- map(eg_run$correlation_tests[[1]][1:3],c('conf.int')) %>% 
  map_df(~data_frame(a = c('lower','upper'), b = .x) %>% spread(a,b))
  
correlations <- correlations %>% 
  bind_cols(cis)

a <- map2_df(eg_run$correlation_tests[[1]][4:6],names(eg_run$correlation_tests[[1]][4:6]),~
            .x %>% 
  gather(classcode, correlation, -rowname) %>% 
  filter(is.na(correlation) == F) %>% 
  left_join(life_history_data %>% select(classcode, targeted), by = c('rowname' = 'classcode')) %>% 
    left_join(life_history_data %>% select(classcode, targeted), by = c('classcode' = 'classcode')) %>% 
  filter(targeted.x == 'Targeted',targeted.y == 'Non-targeted') %>% 
    mutate(correlation_period = .y))

mean_corrs <- a %>% 
  group_by(correlation_period) %>% 
  summarise(mean_correlation = mean(correlation))

a %>% 
  ggplot() + 
  geom_histogram(aes(correlation)) + 
  geom_vline(data = mean_corrs,aes(xintercept = mean_correlation), color = 'red') + 
    geom_vline(aes(xintercept = 0), color = 'blue') + 
  facet_wrap(~correlation_period)

```


We can also look directly at the correlation between abundance and environmental drivers for the fished and unfished species


```{r, fig.cap='Correlation between abundance and ENSO for fished and unfished species'}

foo <- function(x){
  out <- cor(x)[-1,1] %>% as.data.frame()
  blah <- row.names(out)
  out <- out %>% 
    mutate(thing = blah)
  
}

a <- eg_run$data[[1]] %>% 
  select(abundance_index, targeted, contains('enso')) %>% 
  nest(-targeted) %>% 
  mutate(correlation = map(data,foo)) %>% 
  select(targeted,correlation) %>% 
  unnest()

a %>% 
  ggplot() +
  geom_col(aes(thing, ., fill = factor(targeted)), position = 'dodge')

```


```{r, fig.cap='Correlation between abundance and PDO for fished and unfished species'}

foo <- function(x){
  out <- cor(x)[-1,1] %>% as.data.frame()
  blah <- row.names(out)
  out <- out %>% 
    mutate(thing = blah)
  
}

a <- eg_run$data[[1]] %>% 
  select(abundance_index, targeted, contains('pdo')) %>% 
  nest(-targeted) %>% 
  mutate(correlation = map(data,foo)) %>% 
  select(targeted,correlation) %>% 
  unnest()

a %>% 
  ggplot() +
  geom_col(aes(thing, ., fill = factor(targeted)), position = 'dodge')

```


## Abundance Trends

To give an idea of the effect of the "standardization" process, we can compare the hurdle-model standardized indicies of abundance against the simple mean density by year for each of the species in the analysis. We can see that for many species (e.g. painted greenling) the process has neglible effects, while for other species (e.g. blacksmith) the standardization process produces a starkly different estimate of population trajectory. 


```{r, fig.cap='Max scaled abundance indicies for each species in analysis. GLM is standardized abundance, raw is mean of observed densities'}

abundance_comparison <-did_models %>% 
  filter(data_source == 'length_to_density',
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index' |abundance_source == 'raw_abundance_index' ,
         population_filtering == 'all',
         did_term_names == 'years-protected') %>% 
  select(abundance_source, data) %>% 
  unnest()


abundance_comparison %>% 
  group_by(commonname, abundance_source) %>% 
  mutate(abundance_index = abundance_index / max(abundance_index)) %>% 
  ungroup() %>% 
  ggplot(aes(year, abundance_index, color = abundance_source)) + 
  geom_line() + 
  facet_wrap(~commonname) +
  theme_classic() + 
  theme(strip.text = element_text(size = 8))

```


```{r}

bs <- abundance_indices %>% 
  filter(commonname == 'blacksmith',
                  population_structure == 'one-pop',
         population_filtering == 'all')

expected_density <- bs %>% 
  select(data_source, abundance_index) %>% 
  mutate(ed =map(bs$abundance_index, `[`,c('factor_year','linear_predictions'))) %>% 
  select(-abundance_index) %>% 
  unnest()

prob_seen <- bs %>% 
  select(data_source, abundance_index) %>% 
  mutate(ed =map(bs$abundance_index, `[`,c('factor_year','prob_seen'))) %>% 
  select(-abundance_index) %>% 
  unnest()


expected_density %>% 
mutate(year = as.numeric(as.character(factor_year))) %>% 
  group_by(data_source) %>% 
  mutate(linear_predictions = linear_predictions / max(linear_predictions)) %>% 
  ggplot(aes(year, linear_predictions, color = data_source)) + 
  geom_line()

```

```{r}
abundance_comparison <-did_models %>% 
  filter(data_source == 'supplied_density',
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index' |abundance_source == 'raw_abundance_index' ,
         population_filtering == 'all',
         did_term_names == 'years-protected') %>% 
  select(abundance_source, data) %>% 
  unnest()

abundance_comparison %>% 
  group_by(commonname, abundance_source) %>% 
  mutate(abundance_index = abundance_index / max(abundance_index)) %>% 
  ungroup() %>% 
  ggplot(aes(year, abundance_index, color = abundance_source)) + 
  geom_line() + 
  facet_wrap(~commonname) +
  theme_classic() + 
  theme(strip.text = element_text(size = 8))
```


## MPA Effects

With these abundance indicies, we can then fit the DiD estimator side of the model. 

Following earlier examples, we'll look first at the estimated one-population hypothesis, across the potential data sources. 

For all models, at the moment the regression controls for whether or not the species is targeted, the pre-and-post MPA period, lag 0-2 PDO, kelp, temperature, as well as random effects for years and temperature effects by species, along with the relevant DiD estimator.  

```{r, results = 'asis'}
# stargazer::stargazer(eg_run$did_model[[1]])

```



```{r, fig.cap='Estimated MPA effects for different data sources'}

eg_run <-did_models %>% 
  filter(
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index',
         population_filtering == 'all',
         did_term_names == 'years-protected') %>% 
  select(data_source, did_model) %>% 
  mutate(tidy_model = map(did_model, ~broom::tidy(.x))) %>% 
  select(-did_model) %>% 
  unnest() %>% 
  filter(str_detect(term,'did_')) %>% 
  mutate(year = str_replace_all(term,'\\D','') %>% as.numeric())

eg_run %>% 
  ggplot() + 
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_line(aes(year, estimate, color = data_source)) + 
  geom_ribbon(aes(year, ymin = estimate - 1.96 * std.error, ymax = estimate + 1.96 * std.error, fill = data_source), alpha = 0.1)

```

```{r, fig.cap='generations protected'}

eg_run <-did_models %>% 
  filter(
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index',
         population_filtering == 'all',
         did_term_names == 'generations-protected') %>% 
  select(data_source, did_model) %>% 
  mutate(tidy_model = map(did_model, ~broom::tidy(.x))) %>% 
  select(-did_model) %>% 
  unnest() %>% 
  filter(str_detect(term,'did_')) %>% 
  mutate(year = str_replace_all(term,'\\D','') %>% as.numeric())

eg_run %>% 
  ggplot() + 
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_line(aes(year, estimate, color = data_source)) + 
  geom_ribbon(aes(year, ymin = estimate - 1.96 * std.error, ymax = estimate + 1.96 * std.error, fill = data_source), alpha = 0.1)

```

```{r}
eg_run <-did_models %>% 
  filter(
         population_structure == 'regional-pops',
         abundance_source == 'glm_abundance_index',
         population_filtering == 'all',
         did_term_names == 'years-protected') %>% 
  select(data_source, did_model) %>% 
  mutate(tidy_model = map(did_model, ~broom::tidy(.x))) %>% 
  select(-did_model) %>% 
  unnest() %>% 
  filter(str_detect(term,'did_')) %>% 
  mutate(year = str_replace_all(term,'\\D','') %>% as.numeric())

eg_run %>% 
  ggplot() + 
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_line(aes(year, estimate, color = data_source)) + 
  geom_ribbon(aes(year, ymin = estimate - 1.96 * std.error, ymax = estimate + 1.96 * std.error, fill = data_source), alpha = 0.1)
```

```{r}

eg_run <-did_models %>% 
  filter(
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index',
         population_filtering == 'consistent-sites',
         did_term_names == 'years-protected') %>% 
  select(data_source, did_model) %>% 
  mutate(tidy_model = map(did_model, ~broom::tidy(.x))) %>% 
  select(-did_model) %>% 
  unnest() %>% 
  filter(str_detect(term,'did_')) %>% 
  mutate(year = str_replace_all(term,'\\D','') %>% as.numeric())

eg_run %>% 
  ggplot() + 
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_line(aes(year, estimate, color = data_source)) + 
  geom_ribbon(aes(year, ymin = estimate - 1.96 * std.error, ymax = estimate + 1.96 * std.error, fill = data_source), alpha = 0.1)

```

## Alternative Hypotheses

```{r}



```


## Selection on observables

Another tactic out of curiosity. You've got a whole pile of data, what if you just fit the model on selection on observables....


```{r}

eg_run <-did_models %>% 
  filter(
         population_structure == 'one-pop',
         abundance_source == 'glm_abundance_index',
         population_filtering == 'all',
         did_term_names == 'years-protected') %>% 
  select(data_source, data)

did_reg <-
  paste0('log(abundance_index) ~', paste(
    c(
      'targeted',
      'mean_annual_kelp',
      'mean_annual_temp',
      'mean_pdo',
      'lag1_pdo',
      'lag2_pdo',
       'mean_enso',
      'lag1_enso',
      'lag2_enso',
      '(1|factor_year)',
      '((1 + mean_annual_temp)|classcode)'
    ),
    collapse = '+'
  ))

eg_run <- eg_run %>% 
  mutate(did_reg = did_reg) %>% 
  mutate(observables_model = map2(data,did_reg, ~lme4::glmer(.y, data = .x %>% mutate(factor_year = factor(year))))) 

eg_run <- eg_run %>% 
 mutate(tidy_model = map(observables_model, ~broom::tidy(.x))) %>% 
  select(data_source, tidy_model) %>% 
  unnest() %>% 
  filter(str_detect(term,'did_')) %>% 
  mutate(year = str_replace_all(term,'\\D','') %>% as.numeric())  
  
coefficients(eg_run$observables_model[[1]])
```

